{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "title: 'spotPython Tests'\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fun_control_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None)\n",
        "fun_control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def class_attributes_to_dataframe(class_obj):\n",
        "    # Get the attributes and their values of the class object\n",
        "    attributes = [attr for attr in dir(class_obj) if not callable(getattr(class_obj, attr)) and not attr.startswith(\"__\")]\n",
        "    values = [getattr(class_obj, attr) for attr in attributes]\n",
        "    \n",
        "    # Create a DataFrame from the attributes and values\n",
        "    df = pd.DataFrame({'Attribute Name': attributes, 'Attribute Value': values})\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.name = \"John\"\n",
        "        self.age = 30\n",
        "        self.salary = 50000\n",
        "\n",
        "my_instance = MyClass()\n",
        "df = class_attributes_to_dataframe(my_instance)\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "# number of initial points:\n",
        "ni = 7\n",
        "# number of points\n",
        "n = 10\n",
        "\n",
        "fun = analytical().fun_sphere\n",
        "lower = np.array([-1])\n",
        "upper = np.array([1])\n",
        "design_control={\"init_size\": ni}\n",
        "\n",
        "spot_1 = spot.Spot(fun=fun,\n",
        "            lower = lower,\n",
        "            upper= upper,\n",
        "            fun_evals = n,\n",
        "            show_progress=True,\n",
        "            design_control=design_control,)\n",
        "spot_1.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sys import stdout\n",
        "df = spot_1.class_attributes_to_dataframe()\n",
        "stdout.write(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import datasets\n",
        "from river import evaluate\n",
        "from river.linear_model import LogisticRegression\n",
        "from river import metrics\n",
        "from river import optim\n",
        "from river import preprocessing\n",
        "\n",
        "dataset = datasets.Phishing()\n",
        "\n",
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "evaluate.progressive_val_score(dataset, model, metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.csvdataset import CSVDataset\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data.csv', target_column='prognosis')\n",
        "dataset = CSVDataset(target_column='prognosis')\n",
        "print(dataset.data.shape)\n",
        "print(dataset.targets.shape)            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.extra_repr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 3\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV Data set VBDP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the csv_file='./data/spotPython/data.csv' as a pandas df and save it as a pickle file\n",
        "import pandas as pd\n",
        "df = pd.read_csv('./data/spotPython/data.csv')\n",
        "df.to_pickle('./data/spotPython/data.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyHcf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyhcf.data.daten_sensitive import DatenSensitive\n",
        "from pyhcf.utils.names import get_short_parameter_names\n",
        "daten = DatenSensitive()\n",
        "df = daten.load()\n",
        "names =  df.columns\n",
        "names = get_short_parameter_names(names)\n",
        "# rename columns with short names\n",
        "df.columns = names\n",
        "df.head()\n",
        "# save the df as a csv file\n",
        "df.to_csv('./data/spotPython/data_sensitive.csv', index=False)\n",
        "# save the df as a pickle file\n",
        "df.to_pickle('./data/spotPython/data_sensitive.pkl')\n",
        "# remove all rows with NaN values\n",
        "df = df.dropna()\n",
        "# save the df as a csv file\n",
        "df.to_csv('./data/spotPython/data_sensitive_rmNA.csv', index=False)\n",
        "# save the df as a pickle file\n",
        "df.to_pickle('./data/spotPython/data_sensitive_rmNA.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyHcf data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.light.csvdataset import CSVDataset\n",
        "# import torch\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5000\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     # print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.light.csvdataset import CSVDataset\n",
        "# import torch\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5000\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     # print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pickle data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Sensitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(pkl_file='./data/spotPython/data_sensitive.pkl', target_column='A', feature_type=torch.long, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test lightdatamodule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "# dataset = PKLDataset(directory=\"./data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Training set size: {len(data_module.data_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Validation set size: {len(data_module.data_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Test set size: {len(data_module.data_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set the DataModule in fun_control "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_data_module\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=7)\n",
        "dm.setup()\n",
        "set_data_module(fun_control=fun_control,\n",
        "                data_module=dm)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## same with the sensitive data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_data_module\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
        "dm.setup()\n",
        "set_data_module(fun_control=fun_control,\n",
        "                data_module=dm)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## same, but VBDO data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_data_module\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = CSVDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/VBDP/\", filename=\"train.csv\",target_column='prognosis', feature_type=torch.long)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
        "dm.setup()\n",
        "set_data_module(fun_control=fun_control,\n",
        "                data_module=dm)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# load Hyperdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "lhd = LightHyperDict()\n",
        "lhd.hyper_dict\n",
        "user_lhd = LightHyperDict(filename=\"user_hyper_dict.json\", directory=\"./hyperdict/\")\n",
        "user_lhd.hyper_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# add core model to fun control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.netlightbase import NetLightBase\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightBase,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "fun_control[\"core_model\"].__name__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the fun_control[\"core_model_hyper_dict\"] is a LightHyperDict\n",
        "isinstance(fun_control[\"core_model_hyper_dict\"], dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test netlightregression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name           | type   | default   |   lower |   upper | transform             |\n",
            "|----------------|--------|-----------|---------|---------|-----------------------|\n",
            "| l1             | int    | 3         |     5   |    8    | transform_power_2_int |\n",
            "| epochs         | int    | 4         |     2   |    3    | transform_power_2_int |\n",
            "| batch_size     | int    | 4         |     2   |    8    | transform_power_2_int |\n",
            "| act_fn         | factor | ReLU      |     0   |    5    | None                  |\n",
            "| optimizer      | factor | SGD       |     0   |    3    | None                  |\n",
            "| dropout_prob   | float  | 0.01      |     0   |    0.25 | None                  |\n",
            "| lr_mult        | float  | 1.0       |     0.1 |   10    | None                  |\n",
            "| patience       | int    | 2         |     2   |    6    | transform_power_2_int |\n",
            "| initialization | factor | Default   |     0   |    2    | None                  |\n",
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 5.2 K \n",
            "--------------------------------------\n",
            "5.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "5.2 K     Total params\n",
            "0.021     Total estimated model params size (MB)\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric            192.0380096435547\n",
            "        val_loss             192.0380096435547\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 192.0380096435547, 'hp_metric': 192.0380096435547}\n",
            "fun: train_model returned\n",
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 31.7 K\n",
            "--------------------------------------\n",
            "31.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "31.7 K    Total params\n",
            "0.127     Total estimated model params size (MB)\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric               188761008.0\n",
            "        val_loss                188761008.0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 188761008.0, 'hp_metric': 188761008.0}\n",
            "fun: train_model returned\n",
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 12.3 K\n",
            "--------------------------------------\n",
            "12.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "12.3 K    Total params\n",
            "0.049     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric            326.2699279785156\n",
            "        val_loss             326.2699279785156\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 326.2699279785156, 'hp_metric': 326.2699279785156}\n",
            "fun: train_model returned\n",
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 12.3 K\n",
            "--------------------------------------\n",
            "12.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "12.3 K    Total params\n",
            "0.049     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                637604.0\n",
            "        val_loss                 637604.0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 637604.0, 'hp_metric': 637604.0}\n",
            "fun: train_model returned\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric             6045.1591796875\n",
            "        val_loss              6045.1591796875\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 6045.1591796875, 'hp_metric': 6045.1591796875}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [##--------] 20.85% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric               117985112.0\n",
            "        val_loss                117985112.0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 117985112.0, 'hp_metric': 117985112.0}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [##--------] 22.94% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 31.7 K\n",
            "--------------------------------------\n",
            "31.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "31.7 K    Total params\n",
            "0.127     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric               55424216.0\n",
            "        val_loss                55424216.0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 55424216.0, 'hp_metric': 55424216.0}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [##--------] 24.46% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric            350.8734436035156\n",
            "        val_loss             350.8734436035156\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 350.8734436035156, 'hp_metric': 350.8734436035156}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [###-------] 30.20% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 5.2 K \n",
            "--------------------------------------\n",
            "5.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "5.2 K     Total params\n",
            "0.021     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric              204251.328125\n",
            "        val_loss               204251.328125\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 204251.328125, 'hp_metric': 204251.328125}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [####------] 36.05% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 5.2 K \n",
            "--------------------------------------\n",
            "5.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "5.2 K     Total params\n",
            "0.021     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                7630090.5\n",
            "        val_loss                 7630090.5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 7630090.5, 'hp_metric': 7630090.5}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [######----] 55.73% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric            402.1930847167969\n",
            "        val_loss             402.1930847167969\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 402.1930847167969, 'hp_metric': 402.1930847167969}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 192.0380096435547 [######----] 59.20% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric           150.07376098632812\n",
            "        val_loss            150.07376098632812\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': 150.07376098632812, 'hp_metric': 150.07376098632812}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#######---] 68.36% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#######---] 70.55% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#######---] 72.36% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#######---] 74.18% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [########--] 75.95% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [########--] 77.64% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [########--] 79.32% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [########--] 81.13% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [########--] 82.96% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [########--] 84.71% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#########-] 86.51% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#########-] 88.24% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#########-] 89.99% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#########-] 91.70% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [#########-] 93.45% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [##########] 95.19% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [##########] 96.94% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [##########] 98.76% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory runs/lightning_logs/-1707164311427968253/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fun: Calling train_model\n",
            "torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "train_model(): Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric                   nan\n",
            "        val_loss                    nan\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "fun: train_model returned\n",
            "spotPython tuning: 150.07376098632812 [##########] 100.00% Done...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<spotPython.spot.spot.Spot at 0x2ceb66450>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
        "from spotPython.utils.device import getDevice\n",
        "from spotPython.hyperparameters.values import set_data_set\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "from spotPython.light.utils import get_tuned_architecture\n",
        "from spotPython.light.traintest import test_model\n",
        "from spotPython.light.traintest import load_light_from_checkpoint\n",
        "\n",
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "WORKERS = 0\n",
        "PREFIX=\"031\"\n",
        "\n",
        "experiment_name = get_experiment_name(prefix=PREFIX)\n",
        "fun_control = fun_control_init(\n",
        "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
        "    num_workers=WORKERS,\n",
        "    device=getDevice(),\n",
        "    _L_in=133,\n",
        "    _L_out=1,\n",
        "    TENSORBOARD_CLEAN=True)\n",
        "\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
        "set_data_set(fun_control=fun_control,\n",
        "                data_set=dataset)\n",
        "\n",
        "\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[5,8])\n",
        "modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[2,3])\n",
        "modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[2, 8])\n",
        "modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "\n",
        "print(gen_design_table(fun_control))\n",
        "\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")\n",
        "fun = HyperLight(log_level=10).fun\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                       log_level=10,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   max_time = MAX_TIME,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      })\n",
        "spot_tuner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "spot_tuner.plot_progress(log_y=False, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name           | type   | default   |   lower |   upper |   tuned | transform             |   importance | stars   |\n",
            "|----------------|--------|-----------|---------|---------|---------|-----------------------|--------------|---------|\n",
            "| l1             | int    | 3         |     5.0 |     8.0 |     8.0 | transform_power_2_int |         0.00 |         |\n",
            "| epochs         | int    | 4         |     2.0 |     3.0 |     3.0 | transform_power_2_int |         0.00 |         |\n",
            "| batch_size     | int    | 4         |     2.0 |     8.0 |     3.0 | transform_power_2_int |         0.14 | .       |\n",
            "| act_fn         | factor | ReLU      |     0.0 |     5.0 |     2.0 | None                  |         0.00 |         |\n",
            "| optimizer      | factor | SGD       |     0.0 |     3.0 |     0.0 | None                  |         0.00 |         |\n",
            "| dropout_prob   | float  | 0.01      |     0.0 |    0.25 |     0.0 | None                  |         0.00 |         |\n",
            "| lr_mult        | float  | 1.0       |     0.1 |    10.0 |    10.0 | None                  |         0.00 |         |\n",
            "| patience       | int    | 2         |     2.0 |     6.0 |     2.0 | transform_power_2_int |         0.03 |         |\n",
            "| initialization | factor | Default   |     0.0 |     2.0 |     0.0 | None                  |       100.00 | ***     |\n"
          ]
        }
      ],
      "source": [
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "spot_tuner.plot_importance(threshold=0.025, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_tuned_architecture(spot_tuner, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | layers | Sequential | 92.0 K\n",
            "--------------------------------------\n",
            "92.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "92.0 K    Total params\n",
            "0.368     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "******\n",
            "In test_model: torch.Size([2381, 133])\n",
            "torch.Size([2381])\n",
            "Test set size: 1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n",
            "Restoring states from the checkpoint path at /Users/bartz/workspace/spotPython/notebooks/runs/saved_models/-6274069050660873827_TEST/last.ckpt\n",
            "Loaded model weights from the checkpoint at /Users/bartz/workspace/spotPython/notebooks/runs/saved_models/-6274069050660873827_TEST/last.ckpt\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        hp_metric               621.296875\n",
            "        val_loss                621.296875\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "test_model result: {'val_loss': 621.296875, 'hp_metric': 621.296875}\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'mae_loss'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/Users/bartz/workspace/spotPython/notebooks/00_spotPython_tests.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bartz/workspace/spotPython/notebooks/00_spotPython_tests.ipynb#Y143sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_model(config, fun_control)\n",
            "File \u001b[0;32m~/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/spotPython/light/traintest.py:189\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(config, fun_control)\u001b[0m\n\u001b[1;32m    187\u001b[0m test_result \u001b[39m=\u001b[39m test_result[\u001b[39m0\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_model result: \u001b[39m\u001b[39m{\u001b[39;00mtest_result\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[39mreturn\u001b[39;00m test_result[\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m], test_result[\u001b[39m\"\u001b[39;49m\u001b[39mmae_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mae_loss'"
          ]
        }
      ],
      "source": [
        "test_model(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_loaded = load_light_from_checkpoint(config, fun_control)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
